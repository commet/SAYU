#!/usr/bin/env python3
"""
SAYU Wikipedia ÏïÑÌã∞Ïä§Ìä∏ Ï†ïÎ≥¥ ÏàòÏßëÍ∏∞
Python Wikipedia-APIÎ•º ÌôúÏö©Ìïú Ï†ïÎ∞ÄÌïú ÏïÑÌã∞Ïä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë

ÏÑ§Ïπò Î∞©Î≤ï:
pip install wikipedia-api requests psycopg2-binary openai

ÏÇ¨Ïö©Î≤ï:
python wikipediaArtistCollector.py --artist "Pablo Picasso"
python wikipediaArtistCollector.py --batch artists_list.txt
"""

import wikipediaapi
import requests
import json
import re
import sys
import argparse
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
import psycopg2
from psycopg2.extras import RealDictCursor
import openai
import os
from dataclasses import dataclass

# Î°úÍπÖ ÏÑ§Ï†ï
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('artist_collection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class ArtistInfo:
    """ÏïÑÌã∞Ïä§Ìä∏ Ï†ïÎ≥¥ Îç∞Ïù¥ÌÑ∞ ÌÅ¥ÎûòÏä§"""
    name: str
    name_ko: Optional[str] = None
    birth_year: Optional[int] = None
    death_year: Optional[int] = None
    birth_date: Optional[str] = None
    death_date: Optional[str] = None
    nationality: Optional[str] = None
    nationality_ko: Optional[str] = None
    biography: Optional[str] = None
    biography_ko: Optional[str] = None
    art_movement: Optional[str] = None
    birth_place: Optional[str] = None
    death_place: Optional[str] = None
    education: Optional[List[str]] = None
    notable_works: Optional[List[str]] = None
    awards: Optional[List[str]] = None
    influences: Optional[List[str]] = None
    influenced: Optional[List[str]] = None
    spouse: Optional[str] = None
    image_url: Optional[str] = None
    wikipedia_url: Optional[str] = None
    wikidata_id: Optional[str] = None
    categories: Optional[List[str]] = None
    references: Optional[List[str]] = None
    
class WikipediaArtistCollector:
    """Wikipedia APIÎ•º ÌôúÏö©Ìïú Ï†ïÎ∞Ä ÏïÑÌã∞Ïä§Ìä∏ Ï†ïÎ≥¥ ÏàòÏßëÍ∏∞"""
    
    def __init__(self):
        # Wikipedia API ÏÑ§Ï†ï (Îã§Íµ≠Ïñ¥ ÏßÄÏõê)
        self.wiki_en = wikipediaapi.Wikipedia(
            language='en',
            extract_format=wikipediaapi.ExtractFormat.WIKI,
            user_agent='SAYU-ArtCollector/1.0 (https://sayu.life) Data Collection Bot'
        )
        
        self.wiki_ko = wikipediaapi.Wikipedia(
            language='ko',
            extract_format=wikipediaapi.ExtractFormat.WIKI,
            user_agent='SAYU-ArtCollector/1.0 (https://sayu.life) Data Collection Bot'
        )
        
        # OpenAI ÏÑ§Ï†ï
        if os.getenv('OPENAI_API_KEY'):
            openai.api_key = os.getenv('OPENAI_API_KEY')
        
        # Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': os.getenv('DB_PORT', 5432),
            'database': os.getenv('DB_NAME', 'sayu'),
            'user': os.getenv('DB_USER', 'postgres'),
            'password': os.getenv('DB_PASSWORD', '')
        }
        
        # ÏòàÏà† Í¥ÄÎ†® ÌÇ§ÏõåÎìú (Ï†ïÌôïÎèÑ Ìñ•ÏÉÅÏö©)
        self.art_keywords = [
            'painter', 'artist', 'sculptor', 'photographer', 'printmaker',
            'conceptual artist', 'installation artist', 'performance artist',
            'ceramic artist', 'textile artist', 'video artist', 'digital artist'
        ]
        
        # ÏòàÏà† ÏÇ¨Ï°∞ Îß§Ìïë
        self.art_movements = {
            'impressionism': 'Ïù∏ÏÉÅÏ£ºÏùò',
            'expressionism': 'ÌëúÌòÑÏ£ºÏùò', 
            'cubism': 'ÏûÖÏ≤¥Ï£ºÏùò',
            'surrealism': 'Ï¥àÌòÑÏã§Ï£ºÏùò',
            'abstract expressionism': 'Ï∂îÏÉÅÌëúÌòÑÏ£ºÏùò',
            'pop art': 'ÌåùÏïÑÌä∏',
            'minimalism': 'ÎØ∏ÎãàÎ©ÄÎ¶¨Ï¶ò',
            'conceptual art': 'Í∞úÎÖêÎØ∏Ïà†',
            'dadaism': 'Îã§Îã§Ïù¥Ï¶ò',
            'fauvism': 'ÏïºÏàòÏ£ºÏùò',
            'futurism': 'ÎØ∏ÎûòÏ£ºÏùò',
            'constructivism': 'Íµ¨ÏÑ±Ï£ºÏùò'
        }

    def search_artist(self, artist_name: str) -> Optional[ArtistInfo]:
        """
        ÏïÑÌã∞Ïä§Ìä∏ Ïù¥Î¶ÑÏúºÎ°ú Wikipedia Í≤ÄÏÉâ Î∞è Ï†ïÎ≥¥ ÏàòÏßë
        """
        logger.info(f"üé® WikipediaÏóêÏÑú '{artist_name}' Í≤ÄÏÉâ ÏãúÏûë")
        
        try:
            # 1. ÏòÅÎ¨∏ Wikipedia Í≤ÄÏÉâ
            en_page = self.wiki_en.page(artist_name)
            
            if not en_page.exists():
                # Í≤ÄÏÉâÏñ¥ Î≥ÄÌòï ÏãúÎèÑ
                search_results = self.search_variations(artist_name)
                if search_results:
                    en_page = self.wiki_en.page(search_results[0])
                else:
                    logger.warning(f"ÏòÅÎ¨∏ WikipediaÏóêÏÑú '{artist_name}' Ï∞æÏùÑ Ïàò ÏóÜÏùå")
                    return None
            
            # ÏïÑÌã∞Ïä§Ìä∏ Ïó¨Î∂Ä ÌôïÏù∏
            if not self.is_artist_page(en_page):
                logger.warning(f"'{artist_name}'ÏùÄ(Îäî) ÏïÑÌã∞Ïä§Ìä∏Í∞Ä ÏïÑÎãå Í≤ÉÏúºÎ°ú ÌåêÎã®Îê®")
                return None
            
            # 2. Í∏∞Î≥∏ Ï†ïÎ≥¥ Ï∂îÏ∂ú
            artist_info = self.extract_basic_info(en_page)
            
            # 3. ÌïúÍµ≠Ïñ¥ Wikipedia Í≤ÄÏÉâ
            ko_info = self.search_korean_wikipedia(artist_name, artist_info)
            if ko_info:
                artist_info = self.merge_korean_info(artist_info, ko_info)
            
            # 4. Wikidata Ï†ïÎ≥¥ Ï∂îÍ∞Ä
            wikidata_info = self.fetch_wikidata_info(artist_info.wikidata_id)
            if wikidata_info:
                artist_info = self.merge_wikidata_info(artist_info, wikidata_info)
            
            # 5. Ïù¥ÎØ∏ÏßÄ Ï†ïÎ≥¥ ÏàòÏßë
            artist_info.image_url = self.extract_main_image(en_page)
            
            # 6. Ïπ¥ÌÖåÍ≥†Î¶¨ Ï†ïÎ≥¥ Ï∂îÏ∂ú
            artist_info.categories = self.extract_categories(en_page)
            
            # 7. Ï∞∏Í≥† Î¨∏Ìóå Ï∂îÏ∂ú
            artist_info.references = self.extract_references(en_page)
            
            logger.info(f"‚úÖ '{artist_name}' Ï†ïÎ≥¥ ÏàòÏßë ÏôÑÎ£å")
            return artist_info
            
        except Exception as e:
            logger.error(f"‚ùå '{artist_name}' Ï†ïÎ≥¥ ÏàòÏßë Ïã§Ìå®: {str(e)}")
            return None
    
    def is_artist_page(self, page) -> bool:
        """
        ÌéòÏù¥ÏßÄÍ∞Ä ÏïÑÌã∞Ïä§Ìä∏ Í¥ÄÎ†®Ïù∏ÏßÄ ÌôïÏù∏
        """
        content = page.text.lower()
        categories = [cat.lower() for cat in page.categories.keys()]
        
        # ÏïÑÌã∞Ïä§Ìä∏ ÌÇ§ÏõåÎìú ÌôïÏù∏
        for keyword in self.art_keywords:
            if keyword in content[:1000]:  # Ï≤´ 1000ÏûêÏóêÏÑú ÌôïÏù∏
                return True
        
        # Ïπ¥ÌÖåÍ≥†Î¶¨ÏóêÏÑú ÌôïÏù∏
        artist_categories = [
            'artists', 'painters', 'sculptors', 'photographers',
            'american artists', 'french artists', 'british artists',
            'contemporary artists', 'modern artists'
        ]
        
        for cat in categories:
            for art_cat in artist_categories:
                if art_cat in cat:
                    return True
        
        return False
    
    def extract_basic_info(self, page) -> ArtistInfo:
        """
        Wikipedia ÌéòÏù¥ÏßÄÏóêÏÑú Í∏∞Î≥∏ Ï†ïÎ≥¥ Ï∂îÏ∂ú
        """
        content = page.text
        
        artist_info = ArtistInfo(
            name=page.title,
            wikipedia_url=page.fullurl,
            biography=content[:2000] if len(content) > 2000 else content  # Ï≤òÏùå 2000Ïûê
        )
        
        # ÏÉùÎ™∞ÎÖÑÎèÑ Ï∂îÏ∂ú
        birth_death = self.extract_birth_death_dates(content)
        artist_info.birth_year = birth_death.get('birth_year')
        artist_info.death_year = birth_death.get('death_year')
        artist_info.birth_date = birth_death.get('birth_date')
        artist_info.death_date = birth_death.get('death_date')
        
        # Íµ≠Ï†Å Ï∂îÏ∂ú
        artist_info.nationality = self.extract_nationality(content)
        
        # Ï∂úÏÉùÏßÄ Ï∂îÏ∂ú
        artist_info.birth_place = self.extract_birth_place(content)
        
        # ÏòàÏà† ÏÇ¨Ï°∞ Ï∂îÏ∂ú
        artist_info.art_movement = self.extract_art_movement(content)
        
        # Ï£ºÏöî ÏûëÌíà Ï∂îÏ∂ú
        artist_info.notable_works = self.extract_notable_works(content)
        
        # Wikidata ID Ï∂îÏ∂ú
        artist_info.wikidata_id = self.extract_wikidata_id(page)
        
        return artist_info
    
    def extract_birth_death_dates(self, content: str) -> Dict[str, Any]:
        """
        ÏÉùÎ™∞ÎÖÑÎèÑ Ï†ïÎ∞Ä Ï∂îÏ∂ú
        """
        result = {}
        
        # Îã§ÏñëÌïú ÎÇ†Ïßú Ìå®ÌÑ¥
        patterns = [
            # (1881-1973)
            r'\((\d{4})[‚Äì-](\d{4})\)',
            # born 1881, died 1973
            r'born\s+(\d{4}).*?died\s+(\d{4})',
            # 1881‚Äì1973
            r'(\d{4})[‚Äì-](\d{4})',
            # born on 25 October 1881
            r'born\s+(?:on\s+)?(\d{1,2}\s+\w+\s+\d{4})',
            # died 8 April 1973
            r'died\s+(\d{1,2}\s+\w+\s+\d{4})',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                if len(match.groups()) == 2 and match.group(1).isdigit() and match.group(2).isdigit():
                    result['birth_year'] = int(match.group(1))
                    result['death_year'] = int(match.group(2))
                    break
        
        # Í∞úÎ≥Ñ ÎÇ†Ïßú Ìå®ÌÑ¥
        birth_match = re.search(r'born\s+(?:on\s+)?([^,\n]+)', content[:1000], re.IGNORECASE)
        if birth_match:
            result['birth_date'] = birth_match.group(1).strip()
            
        death_match = re.search(r'died\s+([^,\n]+)', content[:1000], re.IGNORECASE)
        if death_match:
            result['death_date'] = death_match.group(1).strip()
        
        return result
    
    def extract_nationality(self, content: str) -> Optional[str]:
        """
        Íµ≠Ï†Å Ï∂îÏ∂ú
        """
        patterns = [
            r'(\w+)\s+(?:painter|artist|sculptor|photographer)',
            r'was\s+a\s+(\w+)',
            r'born\s+in\s+([^,\n]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content[:500], re.IGNORECASE)
            if match:
                nationality = match.group(1).strip()
                # Ïú†Î™ÖÌïú Íµ≠Ï†ÅÎì§ ÌôïÏù∏
                known_nationalities = [
                    'American', 'French', 'Spanish', 'Italian', 'German', 
                    'British', 'Dutch', 'Russian', 'Japanese', 'Korean',
                    'Chinese', 'Mexican', 'Brazilian', 'Indian'
                ]
                if nationality in known_nationalities:
                    return nationality
        
        return None
    
    def extract_birth_place(self, content: str) -> Optional[str]:
        """
        Ï∂úÏÉùÏßÄ Ï∂îÏ∂ú
        """
        pattern = r'born\s+(?:in\s+)?([^,\n\(]+)'
        match = re.search(pattern, content[:1000], re.IGNORECASE)
        if match:
            return match.group(1).strip()
        return None
    
    def extract_art_movement(self, content: str) -> Optional[str]:
        """
        ÏòàÏà† ÏÇ¨Ï°∞ Ï∂îÏ∂ú
        """
        content_lower = content.lower()
        
        for movement, korean in self.art_movements.items():
            if movement in content_lower:
                return movement.title()
        
        return None
    
    def extract_notable_works(self, content: str) -> List[str]:
        """
        Ï£ºÏöî ÏûëÌíà Ï∂îÏ∂ú
        """
        works = []
        
        # "Notable works" ÏÑπÏÖò Ï∞æÍ∏∞
        notable_section = re.search(
            r'(?:notable works?|major works?|famous works?)[:\n](.*?)(?:\n\n|\n[A-Z])', 
            content, 
            re.IGNORECASE | re.DOTALL
        )
        
        if notable_section:
            section_text = notable_section.group(1)
            # ÏûëÌíàÎ™Ö Ìå®ÌÑ¥ (Îî∞Ïò¥ÌëúÎÇò Ïù¥ÌÉ§Î¶≠Ï≤¥)
            work_patterns = [
                r'"([^"]+)"',
                r"'([^']+)'",
                r'\*([^*]+)\*',
                r'_([^_]+)_'
            ]
            
            for pattern in work_patterns:
                matches = re.findall(pattern, section_text)
                works.extend(matches)
        
        return works[:10]  # ÏµúÎåÄ 10Í∞ú
    
    def extract_wikidata_id(self, page) -> Optional[str]:
        """
        Wikidata ID Ï∂îÏ∂ú
        """
        try:
            # Wikipedia APIÎ•º ÌÜµÌï¥ Wikidata ID Í∞ÄÏ†∏Ïò§Í∏∞
            api_url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{page.title}"
            response = requests.get(api_url)
            if response.status_code == 200:
                data = response.json()
                wikibase_item = data.get('wikibase_item')
                if wikibase_item:
                    return wikibase_item
        except Exception as e:
            logger.warning(f"Wikidata ID Ï∂îÏ∂ú Ïã§Ìå®: {e}")
        
        return None
    
    def extract_main_image(self, page) -> Optional[str]:
        """
        Î©îÏù∏ Ïù¥ÎØ∏ÏßÄ URL Ï∂îÏ∂ú
        """
        try:
            # Wikipedia APIÎ•º ÌÜµÌï¥ Ïù¥ÎØ∏ÏßÄ Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Í∏∞
            api_url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{page.title}"
            response = requests.get(api_url)
            if response.status_code == 200:
                data = response.json()
                thumbnail = data.get('thumbnail', {})
                if thumbnail:
                    return thumbnail.get('source')
        except Exception as e:
            logger.warning(f"Ïù¥ÎØ∏ÏßÄ Ï∂îÏ∂ú Ïã§Ìå®: {e}")
        
        return None
    
    def extract_categories(self, page) -> List[str]:
        """
        Wikipedia Ïπ¥ÌÖåÍ≥†Î¶¨ Ï∂îÏ∂ú
        """
        try:
            categories = list(page.categories.keys())
            # ÏïÑÌã∞Ïä§Ìä∏ Í¥ÄÎ†® Ïπ¥ÌÖåÍ≥†Î¶¨Îßå ÌïÑÌÑ∞ÎßÅ
            art_related = []
            for cat in categories:
                cat_lower = cat.lower()
                if any(keyword in cat_lower for keyword in ['artist', 'painter', 'sculptor', 'art']):
                    art_related.append(cat)
            return art_related[:20]  # ÏµúÎåÄ 20Í∞ú
        except Exception as e:
            logger.warning(f"Ïπ¥ÌÖåÍ≥†Î¶¨ Ï∂îÏ∂ú Ïã§Ìå®: {e}")
            return []
    
    def extract_references(self, page) -> List[str]:
        """
        Ï∞∏Í≥† Î¨∏Ìóå Ï∂îÏ∂ú
        """
        try:
            # Í∞ÑÎã®Ìïú ÎßÅÌÅ¨ Ï∂îÏ∂ú
            links = list(page.links.keys())[:10]  # Ï≤òÏùå 10Í∞ú ÎßÅÌÅ¨
            return links
        except Exception as e:
            logger.warning(f"Ï∞∏Í≥† Î¨∏Ìóå Ï∂îÏ∂ú Ïã§Ìå®: {e}")
            return []
    
    def search_korean_wikipedia(self, artist_name: str, artist_info: ArtistInfo) -> Optional[Dict]:
        """
        ÌïúÍµ≠Ïñ¥ Wikipedia Í≤ÄÏÉâ
        """
        try:
            # ÏòÅÎ¨∏Î™ÖÏúºÎ°ú ÌïúÍµ≠Ïñ¥ ÌéòÏù¥ÏßÄ Í≤ÄÏÉâ
            ko_page = self.wiki_ko.page(artist_name)
            
            if ko_page.exists():
                return {
                    'name_ko': ko_page.title,
                    'biography_ko': ko_page.text[:1000] if ko_page.text else None
                }
            
            # Î≤àÏó≠Îêú Ïù¥Î¶ÑÏúºÎ°ú Í≤ÄÏÉâ (OpenAI ÌôúÏö©)
            if os.getenv('OPENAI_API_KEY'):
                translated_name = self.translate_artist_name(artist_name)
                if translated_name:
                    ko_page = self.wiki_ko.page(translated_name)
                    if ko_page.exists():
                        return {
                            'name_ko': ko_page.title,
                            'biography_ko': ko_page.text[:1000] if ko_page.text else None
                        }
        
        except Exception as e:
            logger.warning(f"ÌïúÍµ≠Ïñ¥ Wikipedia Í≤ÄÏÉâ Ïã§Ìå®: {e}")
        
        return None
    
    def translate_artist_name(self, name: str) -> Optional[str]:
        """
        OpenAIÎ•º ÏÇ¨Ïö©Ìïú ÏïÑÌã∞Ïä§Ìä∏ Ïù¥Î¶Ñ Î≤àÏó≠
        """
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": "ÎãπÏã†ÏùÄ ÏòàÏà†Í∞Ä Ïù¥Î¶ÑÏùÑ ÌïúÍµ≠Ïñ¥Î°ú Î≤àÏó≠ÌïòÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§. ÏïÑÌã∞Ïä§Ìä∏ Ïù¥Î¶ÑÎßå ÌïúÍµ≠Ïñ¥Î°ú Î≤àÏó≠Ìï¥ÏÑú ÎãµÎ≥ÄÌï¥Ï£ºÏÑ∏Ïöî."
                    },
                    {
                        "role": "user", 
                        "content": f"Îã§Ïùå ÏïÑÌã∞Ïä§Ìä∏ Ïù¥Î¶ÑÏùÑ ÌïúÍµ≠Ïñ¥Î°ú Î≤àÏó≠Ìï¥Ï£ºÏÑ∏Ïöî: {name}"
                    }
                ],
                max_tokens=50,
                temperature=0.1
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.warning(f"Ïù¥Î¶Ñ Î≤àÏó≠ Ïã§Ìå®: {e}")
            return None
    
    def merge_korean_info(self, artist_info: ArtistInfo, ko_info: Dict) -> ArtistInfo:
        """
        ÌïúÍµ≠Ïñ¥ Ï†ïÎ≥¥ Î≥ëÌï©
        """
        if ko_info.get('name_ko'):
            artist_info.name_ko = ko_info['name_ko']
        if ko_info.get('biography_ko'):
            artist_info.biography_ko = ko_info['biography_ko']
        
        return artist_info
    
    def fetch_wikidata_info(self, wikidata_id: str) -> Optional[Dict]:
        """
        WikidataÏóêÏÑú Ï∂îÍ∞Ä Ï†ïÎ≥¥ ÏàòÏßë
        """
        if not wikidata_id:
            return None
        
        try:
            query = f"""
            SELECT ?item ?itemLabel ?birthDate ?deathDate ?nationalityLabel ?occupationLabel ?educatedAtLabel WHERE {{
              BIND(wd:{wikidata_id} AS ?item)
              OPTIONAL {{ ?item wdt:P569 ?birthDate. }}
              OPTIONAL {{ ?item wdt:P570 ?deathDate. }}
              OPTIONAL {{ ?item wdt:P27 ?nationality. }}
              OPTIONAL {{ ?item wdt:P106 ?occupation. }}
              OPTIONAL {{ ?item wdt:P69 ?educatedAt. }}
              SERVICE wikibase:label {{ bd:serviceParam wikibase:language "en". }}
            }}
            """
            
            url = "https://query.wikidata.org/sparql"
            response = requests.get(url, params={
                'query': query,
                'format': 'json'
            }, headers={
                'User-Agent': 'SAYU-ArtCollector/1.0'
            })
            
            if response.status_code == 200:
                data = response.json()
                bindings = data.get('results', {}).get('bindings', [])
                if bindings:
                    return bindings[0]
            
        except Exception as e:
            logger.warning(f"Wikidata Ï†ïÎ≥¥ ÏàòÏßë Ïã§Ìå®: {e}")
        
        return None
    
    def merge_wikidata_info(self, artist_info: ArtistInfo, wikidata_info: Dict) -> ArtistInfo:
        """
        Wikidata Ï†ïÎ≥¥ Î≥ëÌï©
        """
        # Îçî Ï†ïÌôïÌïú ÎÇ†Ïßú Ï†ïÎ≥¥Í∞Ä ÏûàÏúºÎ©¥ ÏóÖÎç∞Ïù¥Ìä∏
        if 'birthDate' in wikidata_info and wikidata_info['birthDate']['value']:
            birth_date = wikidata_info['birthDate']['value']
            artist_info.birth_date = birth_date
            if not artist_info.birth_year:
                artist_info.birth_year = int(birth_date[:4])
        
        if 'deathDate' in wikidata_info and wikidata_info['deathDate']['value']:
            death_date = wikidata_info['deathDate']['value']
            artist_info.death_date = death_date
            if not artist_info.death_year:
                artist_info.death_year = int(death_date[:4])
        
        # ÍµêÏú° Í∏∞Í¥Ä Ï†ïÎ≥¥
        if 'educatedAtLabel' in wikidata_info:
            if not artist_info.education:
                artist_info.education = []
            artist_info.education.append(wikidata_info['educatedAtLabel']['value'])
        
        return artist_info
    
    def search_variations(self, artist_name: str) -> List[str]:
        """
        ÏïÑÌã∞Ïä§Ìä∏ Ïù¥Î¶Ñ Î≥ÄÌòï Í≤ÄÏÉâ
        """
        try:
            api_url = "https://en.wikipedia.org/api/rest_v1/page/search"
            response = requests.get(api_url, params={
                'q': artist_name,
                'limit': 5
            })
            
            if response.status_code == 200:
                data = response.json()
                pages = data.get('pages', [])
                return [page['title'] for page in pages]
                
        except Exception as e:
            logger.warning(f"Í≤ÄÏÉâ Î≥ÄÌòï Ïã§Ìå®: {e}")
        
        return []
    
    def save_to_database(self, artist_info: ArtistInfo) -> bool:
        """
        Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê ÏïÑÌã∞Ïä§Ìä∏ Ï†ïÎ≥¥ Ï†ÄÏû•
        """
        try:
            conn = psycopg2.connect(**self.db_config)
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            # Ï§ëÎ≥µ ÌôïÏù∏
            cursor.execute(
                "SELECT id FROM artists WHERE LOWER(name) = LOWER(%s)",
                (artist_info.name,)
            )
            
            existing = cursor.fetchone()
            
            if existing:
                # ÏóÖÎç∞Ïù¥Ìä∏
                update_query = """
                UPDATE artists SET
                    name_ko = COALESCE(%s, name_ko),
                    birth_year = COALESCE(%s, birth_year),
                    death_year = COALESCE(%s, death_year),
                    nationality = COALESCE(%s, nationality),
                    nationality_ko = COALESCE(%s, nationality_ko),
                    bio = COALESCE(%s, bio),
                    bio_ko = COALESCE(%s, bio_ko),
                    era = COALESCE(%s, era),
                    images = COALESCE(%s, images),
                    sources = COALESCE(%s, sources),
                    official_links = COALESCE(%s, official_links),
                    updated_at = CURRENT_TIMESTAMP
                WHERE id = %s
                RETURNING id
                """
                
                cursor.execute(update_query, (
                    artist_info.name_ko,
                    artist_info.birth_year,
                    artist_info.death_year,
                    artist_info.nationality,
                    artist_info.nationality_ko,
                    artist_info.biography,
                    artist_info.biography_ko,
                    self.classify_era(artist_info.birth_year, artist_info.death_year),
                    json.dumps({'portrait': artist_info.image_url} if artist_info.image_url else {}),
                    json.dumps({
                        'wikipedia': 'collected',
                        'wikidata': artist_info.wikidata_id
                    }),
                    json.dumps({'wikipedia': artist_info.wikipedia_url} if artist_info.wikipedia_url else {}),
                    existing['id']
                ))
                
                logger.info(f"‚úÖ ÏïÑÌã∞Ïä§Ìä∏ Ï†ïÎ≥¥ ÏóÖÎç∞Ïù¥Ìä∏: {artist_info.name}")
                
            else:
                # ÏÉàÎ°ú ÏÇΩÏûÖ
                insert_query = """
                INSERT INTO artists (
                    name, name_ko, birth_year, death_year, nationality, nationality_ko,
                    bio, bio_ko, copyright_status, era, images, sources, official_links,
                    is_featured
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id
                """
                
                cursor.execute(insert_query, (
                    artist_info.name,
                    artist_info.name_ko,
                    artist_info.birth_year,
                    artist_info.death_year,
                    artist_info.nationality,
                    artist_info.nationality_ko,
                    artist_info.biography,
                    artist_info.biography_ko,
                    self.determine_copyright_status(artist_info),
                    self.classify_era(artist_info.birth_year, artist_info.death_year),
                    json.dumps({'portrait': artist_info.image_url} if artist_info.image_url else {}),
                    json.dumps({
                        'wikipedia': 'collected',
                        'wikidata': artist_info.wikidata_id
                    }),
                    json.dumps({'wikipedia': artist_info.wikipedia_url} if artist_info.wikipedia_url else {}),
                    len(artist_info.notable_works or []) > 5  # Ïú†Î™Ö ÏûëÌíàÏù¥ ÎßéÏúºÎ©¥ featured
                ))
                
                logger.info(f"‚úÖ ÏÉà ÏïÑÌã∞Ïä§Ìä∏ Ï†ïÎ≥¥ Ï†ÄÏû•: {artist_info.name}")
            
            conn.commit()
            cursor.close()
            conn.close()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå DB Ï†ÄÏû• Ïã§Ìå®: {e}")
            return False
    
    def classify_era(self, birth_year: int, death_year: int) -> str:
        """ÏãúÎåÄ Î∂ÑÎ•ò"""
        if not birth_year:
            return 'Contemporary'
        
        active_year = death_year or datetime.now().year
        
        if active_year < 1400:
            return 'Medieval'
        elif active_year < 1600:
            return 'Renaissance'
        elif active_year < 1750:
            return 'Baroque'
        elif active_year < 1850:
            return 'Neoclassicism'
        elif active_year < 1900:
            return 'Impressionism'
        elif active_year < 1945:
            return 'Modern'
        elif active_year < 1980:
            return 'Postmodern'
        else:
            return 'Contemporary'
    
    def determine_copyright_status(self, artist_info: ArtistInfo) -> str:
        """Ï†ÄÏûëÍ∂å ÏÉÅÌÉú ÌåêÎã®"""
        current_year = datetime.now().year
        
        if artist_info.death_year:
            years_since_death = current_year - artist_info.death_year
            if years_since_death >= 70:
                return 'public_domain'
            elif years_since_death >= 50:
                return 'transitional'
            else:
                return 'licensed'
        elif artist_info.birth_year:
            age = current_year - artist_info.birth_year
            if age > 150:
                return 'public_domain'
            else:
                return 'contemporary'
        
        return 'unknown'
    
    def process_batch(self, artist_names: List[str]) -> Dict[str, Any]:
        """
        Î∞∞ÏπòÎ°ú Ïó¨Îü¨ ÏïÑÌã∞Ïä§Ìä∏ Ï≤òÎ¶¨
        """
        results = {
            'successful': [],
            'failed': [],
            'total': len(artist_names)
        }
        
        logger.info(f"üì¶ Î∞∞Ïπò Ï≤òÎ¶¨ ÏãúÏûë: {len(artist_names)}Î™ÖÏùò ÏïÑÌã∞Ïä§Ìä∏")
        
        for i, name in enumerate(artist_names, 1):
            logger.info(f"üé® Ï≤òÎ¶¨ Ï§ë [{i}/{len(artist_names)}]: {name}")
            
            try:
                artist_info = self.search_artist(name)
                if artist_info:
                    if self.save_to_database(artist_info):
                        results['successful'].append({
                            'name': name,
                            'info': artist_info
                        })
                    else:
                        results['failed'].append({
                            'name': name,
                            'error': 'Database save failed'
                        })
                else:
                    results['failed'].append({
                        'name': name,
                        'error': 'Artist not found or not valid'
                    })
                    
            except Exception as e:
                results['failed'].append({
                    'name': name,
                    'error': str(e)
                })
            
            # API Ïú®Ìïú Ï†úÌïú Í≥†Î†§Ìïú ÏßÄÏó∞
            import time
            time.sleep(1)
        
        logger.info(f"üì¶ Î∞∞Ïπò Ï≤òÎ¶¨ ÏôÑÎ£å: ÏÑ±Í≥µ {len(results['successful'])}, Ïã§Ìå® {len(results['failed'])}")
        return results

def main():
    """Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò"""
    parser = argparse.ArgumentParser(description='SAYU Wikipedia ÏïÑÌã∞Ïä§Ìä∏ Ï†ïÎ≥¥ ÏàòÏßëÍ∏∞')
    parser.add_argument('--artist', '-a', help='Îã®Ïùº ÏïÑÌã∞Ïä§Ìä∏ Ïù¥Î¶Ñ')
    parser.add_argument('--batch', '-b', help='ÏïÑÌã∞Ïä§Ìä∏ Î™©Î°ù ÌååÏùº Í≤ΩÎ°ú')
    parser.add_argument('--output', '-o', help='Í≤∞Í≥º Ï†ÄÏû• ÌååÏùº (JSON)', default='artist_results.json')
    
    args = parser.parse_args()
    
    collector = WikipediaArtistCollector()
    
    if args.artist:
        # Îã®Ïùº ÏïÑÌã∞Ïä§Ìä∏ Ï≤òÎ¶¨
        artist_info = collector.search_artist(args.artist)
        if artist_info:
            if collector.save_to_database(artist_info):
                print(f"‚úÖ '{args.artist}' Ï†ïÎ≥¥ ÏàòÏßë Î∞è Ï†ÄÏû• ÏôÑÎ£å")
            else:
                print(f"‚ùå '{args.artist}' DB Ï†ÄÏû• Ïã§Ìå®")
        else:
            print(f"‚ùå '{args.artist}' Ï†ïÎ≥¥ ÏàòÏßë Ïã§Ìå®")
    
    elif args.batch:
        # Î∞∞Ïπò Ï≤òÎ¶¨
        try:
            with open(args.batch, 'r', encoding='utf-8') as f:
                artist_names = [line.strip() for line in f if line.strip()]
            
            results = collector.process_batch(artist_names)
            
            # Í≤∞Í≥º Ï†ÄÏû•
            with open(args.output, 'w', encoding='utf-8') as f:
                # JSON serializable ÌòïÌÉúÎ°ú Î≥ÄÌôò
                serializable_results = {
                    'successful': [
                        {
                            'name': item['name'],
                            'info': {
                                'name': item['info'].name,
                                'birth_year': item['info'].birth_year,
                                'death_year': item['info'].death_year,
                                'nationality': item['info'].nationality,
                                'biography': item['info'].biography[:200] if item['info'].biography else None
                            }
                        } for item in results['successful']
                    ],
                    'failed': results['failed'],
                    'total': results['total'],
                    'success_rate': f"{len(results['successful'])/results['total']*100:.1f}%"
                }
                json.dump(serializable_results, f, ensure_ascii=False, indent=2)
            
            print(f"üìä Í≤∞Í≥ºÍ∞Ä {args.output}Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§")
            print(f"ÏÑ±Í≥µ: {len(results['successful'])}, Ïã§Ìå®: {len(results['failed'])}")
            
        except FileNotFoundError:
            print(f"‚ùå ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {args.batch}")
    
    else:
        parser.print_help()

if __name__ == "__main__":
    main()